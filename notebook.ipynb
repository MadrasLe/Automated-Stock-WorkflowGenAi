{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DC6C-sYTIAIW"
      },
      "outputs": [],
      "source": [
        "# =======================================================================================\n",
        "#               SCRIPT \"DREAM PIPELINE\" V4\n",
        "# =======================================================================================\n",
        "\n",
        "# @title Step 1: Install Dependencies\n",
        "# Keeping essential compatibility fixes for Colab.\n",
        "print(\"Phase 1: Installing dependencies...\")\n",
        "\n",
        "# 1. Unsloth for Llama 3\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\" -q\n",
        "!pip install --no-deps \"trl<0.9.0\" peft accelerate bitsandbytes -q\n",
        "\n",
        "# 2. Diffusers and essential packages\n",
        "!pip install -U diffusers transformers accelerate \"invisible-watermark>=0.2.0\" safetensors --upgrade -q\n",
        "\n",
        "print(\"Dependencies installed. Ready to proceed.\\n\")\n",
        "\n",
        "\n",
        "# Essential Imports\n",
        "import torch\n",
        "from unsloth import FastLanguageModel\n",
        "from diffusers import DiffusionPipeline\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "import re\n",
        "\n",
        "# =======================================================================================\n",
        "#                                 PHASE 1: PROMPT GENERATION\n",
        "# =======================================================================================\n",
        "\n",
        "# @title Step 2: Loading Llama 3 8B\n",
        "print(\"Phase 2: Loading Llama 3 model...\")\n",
        "\n",
        "max_seq_length = 4096\n",
        "dtype = None\n",
        "load_in_4bit = True\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"unsloth/llama-3-8b-Instruct\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    dtype=dtype,\n",
        "    load_in_4bit=load_in_4bit,\n",
        ")\n",
        "print(\"Llama 3 loaded successfully.\\n\")\n",
        "\n",
        "\n",
        "# @title Step 3: Sending Prompt to Llama 3\n",
        "print(\"Phase 3: Generating prompts...\")\n",
        "\n",
        "messages = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are an expert prompt engineer for image AIs like SDXL. Your mission is to create detailed, vivid, and photorealistic prompts perfect for stock photos. Output ONLY the numbered list of prompts, without any introduction or conclusion. Your prompts should be optimized for SDXL's understanding of natural language.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Create a list of 5 highly detailed prompts for stock photos. Focus on business, technology, and nature. Include details on lighting, camera settings (like aperture, lens), and mood. Format it as a numbered list.\"\n",
        "    },\n",
        "]\n",
        "\n",
        "formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    inputs = tokenizer([formatted_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
        "    outputs_tensor = model.generate(**inputs, max_new_tokens=2048, use_cache=True, eos_token_id=tokenizer.eos_token_id)\n",
        "    text_with_prompts = tokenizer.decode(outputs_tensor[0][len(inputs.input_ids[0]):], skip_special_tokens=True)\n",
        "\n",
        "print(\"Prompts generated successfully.\\n\")\n",
        "print(\"--- Generated Prompts ---\")\n",
        "print(text_with_prompts)\n",
        "print(\"-------------------------\\n\")\n",
        "\n",
        "\n",
        "# @title Step 4: Clearing Memory (VRAM)\n",
        "print(\"Phase 4: Unloading Llama 3 to free up memory...\")\n",
        "\n",
        "final_prompts = []\n",
        "for line in text_with_prompts.strip().split('\\n'):\n",
        "    cleaned_line = re.sub(r'^\\d+\\.\\s*', '', line).strip()\n",
        "    if cleaned_line:\n",
        "        final_prompts.append(cleaned_line)\n",
        "\n",
        "del model, tokenizer, inputs, outputs_tensor\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"Memory cleared. {len(final_prompts)} prompts ready.\")\n",
        "print(\"GPU memory released for SDXL.\\n\")\n",
        "\n",
        "# =======================================================================================\n",
        "#                         PHASE 2: IMAGE GENERATION WITH SDXL\n",
        "# =======================================================================================\n",
        "\n",
        "# @title Step 5: Loading SDXL Base and Refiner\n",
        "print(\"Phase 5: Loading SDXL Base and Refiner models...\")\n",
        "print(\"Loading directly to GPU for maximum speed.\")\n",
        "\n",
        "try:\n",
        "    # Loading BASE model and sending to GPU\n",
        "    pipe_base = DiffusionPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "        torch_dtype=torch.float16,\n",
        "        variant=\"fp16\",\n",
        "        use_safetensors=True\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Loading REFINER model and sending to GPU\n",
        "    pipe_refiner = DiffusionPipeline.from_pretrained(\n",
        "        \"stabilityai/stable-diffusion-xl-refiner-1.0\",\n",
        "        text_encoder_2=pipe_base.text_encoder_2,\n",
        "        vae=pipe_base.vae,\n",
        "        torch_dtype=torch.float16,\n",
        "        use_safetensors=True,\n",
        "        variant=\"fp16\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    print(\"SDXL models loaded to GPU.\\n\")\n",
        "\n",
        "    # @title Step 6: Generating Images\n",
        "    print(\"Phase 6: Starting image generation loop...\")\n",
        "\n",
        "    output_dir = \"generated_images_SDXL_max_speed\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Images will be saved in: '{output_dir}'\\n\")\n",
        "\n",
        "    n_steps = 40\n",
        "    high_noise_frac = 0.8\n",
        "\n",
        "    for i, prompt in enumerate(final_prompts):\n",
        "        print(f\"Generating image {i+1}/{len(final_prompts)}...\")\n",
        "        print(f\"  Prompt: {prompt[:80]}...\")\n",
        "\n",
        "        # Generation is faster as everything is in VRAM\n",
        "        image = pipe_base(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=n_steps,\n",
        "            denoising_end=high_noise_frac,\n",
        "            output_type=\"latent\",\n",
        "        ).images\n",
        "\n",
        "        image = pipe_refiner(\n",
        "            prompt=prompt,\n",
        "            num_inference_steps=n_steps,\n",
        "            denoising_start=high_noise_frac,\n",
        "            image=image,\n",
        "        ).images[0]\n",
        "\n",
        "        image_path = os.path.join(output_dir, f\"image_SDXL_turbo_{i+1}.png\")\n",
        "        image.save(image_path)\n",
        "        print(f\"  Image saved at: {image_path}\\n\")\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"Process completed successfully.\")\n",
        "    print(f\"Check the '{output_dir}' folder.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nError encountered: {e}\")\n",
        "    print(\"Ensure you are using a GPU with at least 16GB VRAM (e.g., T4 on Colab Pro or V100).\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import os, signal\n",
        "#os.kill(os.getpid(), signal.SIGKILL)\n",
        "#for gpu vram"
      ],
      "metadata": {
        "id": "PZKixb9QIDMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install super-image\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from super_image import PanModel, ImageLoader\n",
        "from PIL import Image\n",
        "from tqdm import tqdm  # For progress bar visualization\n",
        "\n",
        "# Settings\n",
        "input_folder = '/content/generated_images_SDXL_max_speed'  # Change to your folder path\n",
        "output_folder = '/content/upscaled_folder/'  # Folder to save upscaled images\n",
        "scale_factor = 4  # 2, 3, or 4 - change as needed\n",
        "os.makedirs(output_folder, exist_ok=True)  # Creates folder if it doesn't exist\n",
        "\n",
        "# Load model on GPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Running on device: {device}\")\n",
        "\n",
        "model = PanModel.from_pretrained('eugenesiow/pan-bam', scale=scale_factor)\n",
        "model = model.to(device)  # Move model to GPU\n",
        "model.eval()  # Inference mode\n",
        "\n",
        "# List images in the folder (only .jpg and .png)\n",
        "image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.png'))]\n",
        "\n",
        "# Loop with progress bar\n",
        "for filename in tqdm(image_files, desc=\"Upscaling images\"):\n",
        "    input_path = os.path.join(input_folder, filename)\n",
        "    output_path = os.path.join(output_folder, f\"up_{filename}\")\n",
        "\n",
        "    # Load image\n",
        "    image = Image.open(input_path)\n",
        "\n",
        "    # Prepare input on GPU\n",
        "    inputs = ImageLoader.load_image(image).to(device)\n",
        "\n",
        "    # Inference on GPU\n",
        "    with torch.no_grad():\n",
        "        preds = model(inputs)\n",
        "\n",
        "    # Save (automatically handles moving back to CPU)\n",
        "    ImageLoader.save_image(preds, output_path)\n",
        "    print(f\"Upscaled: {output_path}\")\n",
        "\n",
        "print(\"Done! All images upscaled in the output folder.\")"
      ],
      "metadata": {
        "id": "ZdEtbUFIIE8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Version 2.2 - TXT and CSV export support\n",
        "!pip install transformers==4.51.0\n",
        "import os\n",
        "import spacy\n",
        "import csv\n",
        "from transformers import AutoProcessor, AutoModelForCausalLM\n",
        "from PIL import Image\n",
        "import torch\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Load spaCy model\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "except OSError:\n",
        "    print(\"Downloading spaCy model 'en_core_web_sm' for the first time...\")\n",
        "    spacy.cli.download(\"en_core_web_sm\")\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "class DreamstimeUploadAutomator:\n",
        "    def __init__(self, image_folder, categories, num_threads=4):\n",
        "        self.image_folder = image_folder\n",
        "        self.categories = categories\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Using device: {self.device}\")\n",
        "        self.processor, self.model = self.configure_models()\n",
        "        self.num_threads = num_threads\n",
        "        self.model.to(self.device)\n",
        "\n",
        "    def configure_models(self):\n",
        "        print(\"Loading Florence-2-base model...\")\n",
        "        model_id = 'microsoft/Florence-2-base'\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True).eval()\n",
        "        processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
        "        return processor, model\n",
        "\n",
        "    def generate_keywords(self, description, max_keywords=50, min_length=3):\n",
        "        doc = nlp(description.lower())\n",
        "        keywords = set()\n",
        "        for token in doc:\n",
        "            if token.pos_ in [\"NOUN\", \"ADJ\", \"PROPN\"] and not token.is_stop and len(token.text) >= min_length:\n",
        "                keywords.add(token.text)\n",
        "        for chunk in doc.noun_chunks:\n",
        "            clean_chunk = ' '.join(token.text for token in chunk if not token.is_stop and token.pos_ in [\"NOUN\", \"ADJ\", \"PROPN\"])\n",
        "            if len(clean_chunk) > min_length:\n",
        "                keywords.add(clean_chunk)\n",
        "        return ', '.join(list(keywords)[:max_keywords])\n",
        "\n",
        "    def analyze_image(self, image_path):\n",
        "        try:\n",
        "            image = Image.open(image_path).convert(\"RGB\")\n",
        "            task_prompt = \"<MORE_DETAILED_CAPTION>\"\n",
        "            inputs = self.processor(text=task_prompt, images=image, return_tensors=\"pt\").to(self.device)\n",
        "            generated_ids = self.model.generate(\n",
        "                input_ids=inputs[\"input_ids\"],\n",
        "                pixel_values=inputs[\"pixel_values\"],\n",
        "                max_new_tokens=1024,\n",
        "                num_beams=3,\n",
        "                do_sample=False\n",
        "            )\n",
        "            generated_text = self.processor.batch_decode(generated_ids, skip_special_tokens=False)[0]\n",
        "            parsed_answer = self.processor.post_process_generation(generated_text, task=task_prompt, image_size=image.size)\n",
        "            description = parsed_answer.get(task_prompt, \"Could not generate description.\")\n",
        "            title = ' '.join(description.split()[:15])\n",
        "            keywords = self.generate_keywords(description)\n",
        "\n",
        "            return {\n",
        "                'description': description.capitalize(),\n",
        "                'title': title.capitalize(),\n",
        "                'keywords': keywords\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"\\nError analyzing image {os.path.basename(image_path)}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def process_image_batch(self, filename):\n",
        "        full_path = os.path.join(self.image_folder, filename)\n",
        "        analysis = self.analyze_image(full_path)\n",
        "        return filename, analysis\n",
        "\n",
        "    def generate_output_files(self):\n",
        "        \"\"\"\n",
        "        Writes both TXT and CSV files.\n",
        "        \"\"\"\n",
        "        base_name = \"dreamstime_upload_florence2_base\"\n",
        "        txt_filename = f\"{base_name}.txt\"\n",
        "        csv_filename = f\"{base_name}.csv\"\n",
        "\n",
        "        images_to_process = [f for f in os.listdir(self.image_folder)\n",
        "                               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        if not images_to_process:\n",
        "            print(\"No images found in the folder.\")\n",
        "            return\n",
        "\n",
        "        print(f\"\\nFound {len(images_to_process)} images. Processing with Florence-2-base...\")\n",
        "\n",
        "        data_for_csv = []\n",
        "\n",
        "        with open(txt_filename, \"w\", encoding=\"utf-8\") as txt_file, ThreadPoolExecutor(max_workers=self.num_threads) as executor:\n",
        "            future_results = {executor.submit(self.process_image_batch, img): img for img in images_to_process}\n",
        "\n",
        "            for future in tqdm(future_results, total=len(images_to_process), desc=\"Analyzing images\"):\n",
        "                filename, analysis = future.result()\n",
        "                if analysis is None:\n",
        "                    continue\n",
        "\n",
        "                # --- Preparing Data ---\n",
        "                image_data = {\n",
        "                    'Filename': filename,\n",
        "                    'Image Name': f\"{analysis['title']} generated\",\n",
        "                    'Descriptions': analysis['description'],\n",
        "                    'Keywords': analysis['keywords'],\n",
        "                    'Category 1': self.categories[0] if len(self.categories) > 0 else '',\n",
        "                    'Category 2': self.categories[1] if len(self.categories) > 1 else '',\n",
        "                    'Category 3': self.categories[2] if len(self.categories) > 2 else '',\n",
        "                    'Free': 0, 'W-EL': 1, 'P-EL': 1, 'SR-EL': 1, 'SR-Price': 100\n",
        "                }\n",
        "\n",
        "                # --- Writing to .txt file ---\n",
        "                for key, value in image_data.items():\n",
        "                    txt_file.write(f\"{key}: {value}\\n\")\n",
        "                txt_file.write(\"\\n\") # Separator line\n",
        "\n",
        "                # --- Storing data for CSV ---\n",
        "                data_for_csv.append(image_data)\n",
        "\n",
        "        # --- Creating CSV file ---\n",
        "        if data_for_csv:\n",
        "            print(\"Creating CSV file...\")\n",
        "            headers = data_for_csv[0].keys()\n",
        "\n",
        "            with open(csv_filename, \"w\", encoding=\"utf-8\", newline='') as csv_file:\n",
        "                writer = csv.DictWriter(csv_file, fieldnames=headers)\n",
        "                writer.writeheader()\n",
        "                writer.writerows(data_for_csv)\n",
        "\n",
        "        print(f\"\\nFiles created successfully:\")\n",
        "        print(f\" -> {txt_filename}\")\n",
        "        print(f\" -> {csv_filename}\")\n",
        "\n",
        "def request_image_path():\n",
        "    while True:\n",
        "        path = input(\"Enter the full path to your images folder: \").strip()\n",
        "        if os.path.isdir(path):\n",
        "            return path\n",
        "        else:\n",
        "            print(\"Invalid path. Please verify and try again.\")\n",
        "\n",
        "def request_categories():\n",
        "    categories = []\n",
        "    print(\"\\nEnter up to 3 categories for your images (e.g., Abstract, Technology, Nature):\")\n",
        "    for i in range(3):\n",
        "        category = input(f\"Category {i+1} (press Enter to skip): \").strip()\n",
        "        if category:\n",
        "            categories.append(category)\n",
        "    return categories\n",
        "\n",
        "def main():\n",
        "    print(\"===========================================\")\n",
        "    print(\"=== Dreamstime Upload Automation v2.2 ===\")\n",
        "    print(\"      -- Exports to TXT and CSV --\")\n",
        "    print(\"===========================================\")\n",
        "\n",
        "    image_folder = request_image_path()\n",
        "    categories = request_categories()\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            num_threads_str = input(\"\\nEnter number of threads (3 or 4 recommended): \")\n",
        "            num_threads = int(num_threads_str)\n",
        "            if num_threads > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Please enter a number greater than zero.\")\n",
        "        except ValueError:\n",
        "            print(\"Invalid input. Please enter a number.\")\n",
        "\n",
        "    automator = DreamstimeUploadAutomator(image_folder, categories, num_threads)\n",
        "    automator.generate_output_files()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "b5ydOu1_IGGe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}